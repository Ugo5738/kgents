# Tool Registry Service

The Tool Registry Service is a microservice in the Kgents platform responsible for managing, cataloging, and executing tools that can be used by agents across the platform.

## Features

- Tool registration and management
- Tool categorization and searchability
- Secure execution in sandboxed environments
- Tool execution history tracking
- Support for multiple tool types:
  - HTTP/API tools
  - Python code
  - JavaScript code
  - Command-line tools

## Architecture

The Tool Registry Service follows the microservice architecture pattern established in the Kgents platform:

- FastAPI for API development
- Async SQLAlchemy 2.0 for database operations
- Pydantic for data validation and schemas
- JWT authentication with Auth Service integration
- PostgreSQL as the primary data store

## Development Setup

### Prerequisites

- Docker and Docker Compose
- Python 3.12+
- Poetry for dependency management

### Local Development

1. Clone the repository
2. Install dependencies with Poetry:
   ```bash
   poetry install
   ```
3. Set up environment variables (copy from `.env.example` to `.env.dev`)
4. Start the development server:
   ```bash
   # From the project root
   docker-compose -f docker-compose.dev.yml up -d
   ```

## Database Migrations

The service uses Alembic for database schema migrations, which are managed through our custom script that supports both development and production environments.

### Environment-Specific Operations

```bash
# Create a migration for development environment
python scripts/manage_migrations.py generate "description_of_changes" --env=dev

# Apply migrations to development database
python scripts/manage_migrations.py upgrade --env=dev

# Create/manage production database
python scripts/manage_migrations.py create-db --env=prod
python scripts/manage_migrations.py upgrade --env=prod
```

### Database Lifecycle Management

```bash
# Create a database for the specified environment
python scripts/manage_migrations.py create-db --env=dev

# Drop a database for the specified environment
python scripts/manage_migrations.py drop-db --env=dev

# Reset (drop and recreate) a database
python scripts/manage_migrations.py reset-db --env=dev
```

See the [detailed migration documentation](docs/development/README.md#database-migrations) for more information on working with multiple environments.

### Creating a New Migration

To create a new migration from model changes:

```bash
# Navigate to the service directory
cd tool_registry_service

# Generate a new migration with autogenerate
docker-compose -f docker-compose.dev.yml exec tool_registry_service_dev \
  alembic revision --autogenerate -m "description_of_changes"
```

### Running Migrations

To apply migrations:

```bash
# Apply all pending migrations
docker-compose -f docker-compose.dev.yml exec tool_registry_service_dev \
  alembic upgrade head

# Apply specific migration
docker-compose -f docker-compose.dev.yml exec tool_registry_service_dev \
  alembic upgrade <revision>

# Roll back migrations
docker-compose -f docker-compose.dev.yml exec tool_registry_service_dev \
  alembic downgrade <revision>
```

### Migration Best Practices

1. Always review autogenerated migrations before applying them
2. Test migrations in development before applying to production
3. Use meaningful migration names that describe the purpose (e.g., "add_tool_execution_table")
4. Keep migrations idempotent and reversible when possible

## Testing

Run tests with pytest:

```bash
# Run all tests
docker-compose -f docker-compose.test.yml up --build

# Run specific tests
docker-compose -f docker-compose.test.yml exec tool_registry_service_test \
  pytest tests/unit/test_specific_file.py
```

## API Documentation

When running the service, API documentation is available at:

- OpenAPI Docs: `http://localhost:8003/api/docs`
- ReDoc: `http://localhost:8003/api/redoc`

## Security Considerations

- Tools are always executed in sandboxed environments
- Command-line tool execution has additional security constraints
- All tool executions are logged and tracked
- Authentication is required for all API endpoints except public tool listings
- Tools can be marked as public or private
- Admin approval is required for public tools
